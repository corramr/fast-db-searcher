{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a58556",
   "metadata": {},
   "source": [
    "# Fast Db Searcher\n",
    "This Jupyter notebook aims to convert natural language queries into SQL statements, leveraging a large language model (LLM). The goal is to accomplish this using the `Llama 3.3 8B model` while minimizing the number of LLM calls, therefore reducing latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf17cc8",
   "metadata": {},
   "source": [
    "The notebok is divided in two main section, a `router section` and a `converter section`. The `router section` will decide which table(s) needs to be queried, while the `converter section` will actually perform the translation from natural language to sql statements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd386a9",
   "metadata": {},
   "source": [
    "![intro_schema](images/general_schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5928d3a",
   "metadata": {},
   "source": [
    "Only the converter section leverages LLM while the router section exploits semantic similarity to pick the proper tables in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688e5b1",
   "metadata": {},
   "source": [
    "For sake of simplicity, we'll be working with a simple fake database made of 2 tables. A table regarding `countries` data and one regarding `cars` data. \n",
    "The router will decide which tables to be queried according the human query. If the natural language query is categorized under the \"countries\" topic, the \"country\" table will be queried, if the natural language query is categorized  under the \"cars\" topic, the \"cars\" table will be queried. In addition, if the natural language query is NOT categorized either under the \"countries\" topic nor under the \"cars\" topic, no tables will be queried. Finally the converter will do the job of converting the natural language query in SQL query based on the information of the chosen table (table schema, table sample, ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b7cdf3",
   "metadata": {},
   "source": [
    "## Router\n",
    "As we mentioned earlier, the purpose of the router is to decide whether a human query refers to the to `countries` topic, `cars` topic or if it refers to no topic at all.\n",
    "\n",
    "To accomplish this task, we leverage a library called `semantic router`. The `semantic router` library allows to assess whether a natural language query is related to a specific topic by comparing the query with some utterances. The utterances are specific verbal expressions used to define the semantic field that we want to enclose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f686d8bd",
   "metadata": {},
   "source": [
    "![SEMANTIC_ROUTER_SCHEMA](images/semantic_router_schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad5b91",
   "metadata": {},
   "source": [
    "In simple words, the query is compared to each utterance by vector similarity. Therefore, a similarity score is computed between each utterance and query. Based on the similarity score, the router will decides if the query belongs to the cars topic, countries topic or none of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc039c22",
   "metadata": {},
   "source": [
    "Now let's get to the code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef137712",
   "metadata": {},
   "source": [
    "Install the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949f40b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093d505",
   "metadata": {},
   "source": [
    "Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3707ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_router import Route\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "from semantic_router.routers import SemanticRouter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7bb4f4",
   "metadata": {},
   "source": [
    "Define the encoder to create embeddings for queries and utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01450c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "encoder = OpenAIEncoder(score_threshold=0.16) # you can tune this parameter to steer the performance of your router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e30f55",
   "metadata": {},
   "source": [
    "Define the utterances for countries data and cars data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49a16e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAR_UTTERANCES = [\n",
    "    \"car\",\n",
    "    \"vehicle\",\n",
    "    \"engine\",\n",
    "    \"speed\",\n",
    "    \"drive\",\n",
    "    \"wheels\",\n",
    "    \"fuel\",\n",
    "    \"horsepower\",\n",
    "    \"brake\",\n",
    "    \"race\",\n",
    "    \"ratings\",\n",
    "    \"manufacture\",\n",
    "    \"steering wheel\",\n",
    "    \"dashboard\",\n",
    "    \"acceleration\",\n",
    "    \"sales\",\n",
    "    \"production\",\n",
    "    \"kilometer\"\n",
    "]\n",
    "\n",
    "COUNTRIES_UTTERANCES = [\n",
    "    \"land\",\n",
    "    \"nation\",\n",
    "    \"country\",\n",
    "    \"homeland\",\n",
    "    \"flag\",\n",
    "    \"borders\",\n",
    "    \"culture\",\n",
    "    \"history\",\n",
    "    \"cuisine\",\n",
    "    \"traditions\",\n",
    "    \"rivers\",\n",
    "    \"cities\",\n",
    "    \"passport\",\n",
    "    \"landscape\",\n",
    "    \"mountains\",\n",
    "    \"fauna\", \n",
    "    \"flora\",\n",
    "    \"government\",\n",
    "    \"capital\",\n",
    "    \"citizen\",\n",
    "    \"language\",\n",
    "    \"economy\",\n",
    "    \"currency\",\n",
    "    \"anthem\",\n",
    "    \"constitution\"\n",
    "    \"population\",\n",
    "    \"forest\",\n",
    "    \"desert\",\n",
    "    \"coastline\",\n",
    "    \"military\",\n",
    "    \"politics\",\n",
    "    \"province\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b308c9",
   "metadata": {},
   "source": [
    "Define routes based on the utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c254f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = Route(name=\"cars\", utterances=CAR_UTTERANCES)\n",
    "countries = Route(name=\"countries\", utterances=COUNTRIES_UTTERANCES)\n",
    "routes = [cars, countries]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad9845",
   "metadata": {},
   "source": [
    "Define the router based on the encoder and the routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e1b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl = SemanticRouter(encoder=encoder, routes=routes, auto_sync=\"local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe6eaf",
   "metadata": {},
   "source": [
    "Now it is all set! We can test the router on a bunch of queries, For this example we will use the queries in queries.json. This file contains 10 queries about the cars data, 10 queries about the countries data and 10 queries about unrelated topics. We will run the router on this 30 queries and create a report to evaluate the performance of the router. The report is saved under the name report.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f337e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load queries\n",
    "with open(\"queries.json\", \"r\") as file:\n",
    "    queries = json.load(file)\n",
    "\n",
    "# build report\n",
    "report = []\n",
    "\n",
    "for query in tqdm(queries, desc=\"Processing questions\"):\n",
    "    route = rl(query[\"query\"]).name\n",
    "\n",
    "    # fill out report\n",
    "    report.append(\n",
    "        {\n",
    "            \"query\": query[\"query\"],\n",
    "            \"category\": query[\"category\"],\n",
    "            \"route\": route,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "# Save report\n",
    "with open(\"report.json\", \"w\") as file:\n",
    "    file.write(json.dumps(report, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ad68f",
   "metadata": {},
   "source": [
    "Let's comment the results of the report. The 10 queries about cars were correctly categorized under the cars topic. On the other hand, for what concerns the countries queries, 9/10 were correctly categorized under the country topic. Finally, about the unrelated queries, only 7/10 were correctly categorized as unrelated.\n",
    "\n",
    "Let's have a closer look at what the router misclassified to see if we can improve its performance. Consider the following query:\n",
    "\n",
    "`{\n",
    "    \"query\": \"In which place is the horse the most common animal?\",\n",
    "    \"category\": \"countries\",\n",
    "    \"route\": \"cars\"\n",
    "},`\n",
    "\n",
    "This query refers to country data but it is categorized under the cars topic by the router. Why? If I look up at my countries utterances, I see that I included the word \"fauna\" so I'm expecting the router to categorize this query properly. However, If I look also at the car utterances, I see the word \"horsepower\", so that's what led the router to misclassify the query. \n",
    "\n",
    "Consider this other query:\n",
    "\n",
    "`{\n",
    "    \"query\": \"Explain the theory of relativity.\",\n",
    "    \"category\": \"unrelated\",\n",
    "    \"route\": \"cars\"\n",
    "},`\n",
    "\n",
    "This query is clearly not related to \"countries\" and \"cars\" topics but it was erraneously categorized under the cars topic by the router. Why? It's probably due to the word \"speed\" appearing in the car utterances. The theory of relativity is strictly related to the speed of light, thus leading the router to misclassify the query. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03953c88",
   "metadata": {},
   "source": [
    "Is there a way to fix this? We can try to work on the utterances. Let's redefine the utterances in the following way:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfc6e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAR_UTTERANCES = [\n",
    "    \"fuel sales vehicle speed\",\n",
    "    \"sales ratings engine horsepower\",\n",
    "    \"brake steering wheel manufacture acceleration\",\n",
    "    \"race brake vehicle engine\",\n",
    "    \"fuel sales acceleration brake\",\n",
    "    \"acceleration kilometer brake sales\",\n",
    "    \"dashboard fuel wheels car\",\n",
    "    \"vehicle manufacture drive horsepower\",\n",
    "    \"ratings dashboard vehicle production\",\n",
    "    \"race kilometer drive vehicle\",\n",
    "    \"drive car engine speed\",\n",
    "    \"production manufacture vehicle wheels\",\n",
    "    \"fuel race horsepower speed\",\n",
    "    \"ratings steering wheel race acceleration\",\n",
    "    \"drive manufacture speed kilometer\",\n",
    "    \"brake acceleration dashboard manufacture\",\n",
    "    \"steering wheel vehicle manufacture kilometer\",\n",
    "    \"manufacture car horsepower wheels\",\n",
    "    \"race fuel speed brake\",\n",
    "    \"car dashboard fuel sales\",\n",
    "    \"manufacture production race speed\",\n",
    "    \"brake manufacture acceleration drive\",\n",
    "    \"steering wheel brake fuel ratings\",\n",
    "    \"steering wheel drive dashboard production\",\n",
    "    \"car speed sales race\",\n",
    "    \"ratings steering wheel sales manufacture\",\n",
    "    \"fuel drive acceleration brake\",\n",
    "    \"drive ratings engine speed\",\n",
    "    \"wheels drive vehicle acceleration\",\n",
    "    \"dashboard sales manufacture acceleration\",\n",
    "]\n",
    "\n",
    "COUNTRIES_UTTERANCES = [\n",
    "    \"flag province cities coastline\",\n",
    "    \"land traditions fauna citizen\",\n",
    "    \"fauna anthem homeland cuisine\",\n",
    "    \"military nation flora borders\",\n",
    "    \"flag military forest coastline\",\n",
    "    \"mountains culture currency rivers\",\n",
    "    \"cities desert capital politics\",\n",
    "    \"flora culture government homeland\",\n",
    "    \"anthem land flag culture\",\n",
    "    \"military culture currency cuisine\",\n",
    "    \"flora cities coastline anthem\",\n",
    "    \"province flora citizen land\",\n",
    "    \"nation country currency coastline\",\n",
    "    \"province flora mountains desert\",\n",
    "    \"language cities flag constitutionpopulation\",\n",
    "    \"government military homeland flora\",\n",
    "    \"politics flora mountains capital\",\n",
    "    \"constitutionpopulation economy anthem currency\",\n",
    "    \"country nation anthem traditions\",\n",
    "    \"fauna coastline province culture\",\n",
    "    \"flag currency fauna military\",\n",
    "    \"economy culture politics cities\",\n",
    "    \"province currency desert land\",\n",
    "    \"flora traditions cuisine passport\",\n",
    "    \"passport homeland anthem capital\",\n",
    "    \"economy citizen capital cuisine\",\n",
    "    \"forest anthem capital country\",\n",
    "    \"nation country forest anthem\",\n",
    "    \"citizen cuisine coastline history\",\n",
    "    \"history language economy culture\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c48809",
   "metadata": {},
   "source": [
    "As shown above, we redefined the utterances for each category. Each utterance is a random combination of the 4 elements taken from the previous single utterances. In this way the concept of the speed will be more closely related to the cars topic by utterances such as \"drive car engine speed\". The same goes for the concept of horsepower: its relation with the car world will be further increased by utterances such as \"fuel race horsepower speed\". In simple words, we enforced the utterances to be closely related to their topics of interest (cars and countries).\n",
    "\n",
    "Let's now redefine the routes, redefine the router and run the test once again. Now we can see the that each query was correctly categorized by the router!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdfb7ac",
   "metadata": {},
   "source": [
    "## Converter\n",
    "Now that we know on which table we have to work on, we can easily convert the natural language query into sql query by carefully prompting the large language model. The core idea is to build a prompt with all the necessary ingredients: natural language query, schema of table(s) of interest, and sample data of the table(s) of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f695cc2c",
   "metadata": {},
   "source": [
    "Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a75f719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from utils.helper import get_column_info, get_table_sample\n",
    "import json\n",
    "import sqlite3\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cab37d",
   "metadata": {},
   "source": [
    "Define the test query and compute its route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28cd0ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:00:34 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "route: cars\n"
     ]
    }
   ],
   "source": [
    "test_query = \"Who between Vortex X1 and Avalon S has the highest fuel consumption?\"\n",
    "query_route = rl(test_query).name\n",
    "print(f\"route: {query_route}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca59447a",
   "metadata": {},
   "source": [
    "Get the info of the table of interest according to the route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8949223",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"data/data.db\"\n",
    "if query_route == \"cars\":\n",
    "    table_name = \"cars_data\"\n",
    "    column_info = get_column_info(db_path, \"cars_data\")\n",
    "    table_sample = get_table_sample(db_path, \"cars_data\")\n",
    "\n",
    "elif query_route == \"countries\":\n",
    "    table_name = \"countries_data\"\n",
    "    column_info = get_column_info(db_path, \"countries_data\")\n",
    "    table_sample = get_table_sample(db_path, \"countries_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a5bbbf",
   "metadata": {},
   "source": [
    "Define the template of the prompt to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e3eb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "NL2SQL_TEMPLATE = \"\"\"\n",
    "You are a software engineer specialized in converting natural language query to SQL query. Follow closely the provided instructions. \n",
    "\n",
    "# Instructions\n",
    "- Always look up closely to the 'database info' section before converting the natural language query into a SQL query\n",
    "- Always follow the provided output format\n",
    "- ONLY include the SQL query to the user in your response\n",
    "\n",
    "# Database info\n",
    "<column_info table_name=\"{table_name}\">\n",
    "Info about the columns of the table:\n",
    "{column_info}\n",
    "</column_info>\n",
    "\n",
    "<table_sample table_name=\"{table_name}\">\n",
    "The first three rows of the table:\n",
    "{table_sample}\n",
    "</table_sample>\n",
    "\n",
    "# Output format\n",
    "Always provide the response according to the following output format:\n",
    "{{\"sql_query\": <sql_query>}}\n",
    "\n",
    "# Natural language query\n",
    "{nl_query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9a53e4",
   "metadata": {},
   "source": [
    "Notice that the above template is scalable with respect to the number of tables involved since the \"database info\" section can be modified to account for multiple tables as long as we enclose them in the proper XML tags. For this case scenario we only have 1 table per topic, so it's okay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e971e",
   "metadata": {},
   "source": [
    "Now let's define the prompt and the large language model. As we anticipated in the beginning of the notebook, the employed model is Llama-3.3-8b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbfb3603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-18 17:00:47 - httpx - INFO - _client.py:1025 - _send_single_request() - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sql_query\": \"SELECT car_name, fuel_consumption FROM cars_data WHERE car_name IN ('Vortex X1', 'Avalon S') ORDER BY fuel_consumption DESC LIMIT 1\"}\n"
     ]
    }
   ],
   "source": [
    "# build prompt\n",
    "prompt = NL2SQL_TEMPLATE.format(\n",
    "    table_name=table_name,\n",
    "    table_sample=table_sample,\n",
    "    column_info=column_info,\n",
    "    nl_query=test_query,\n",
    ")\n",
    "\n",
    "# define and invoke LLM\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"meta-llama/llama-3.3-8b-instruct:free\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": prompt\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "response = completion.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c26f0c7",
   "metadata": {},
   "source": [
    "Extract the SQL query from the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0be79d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dictionary = json.loads(response)\n",
    "sql_query = response_dictionary[\"sql_query\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a558170",
   "metadata": {},
   "source": [
    "Run the SQL in your database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4c92fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL Query Result:\n",
      "('Vortex X1', '7.5L/100km')\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(sql_query)\n",
    "result = cursor.fetchall()\n",
    "print(\"SQL Query Result:\")\n",
    "for row in result:\n",
    "    print(row)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c59b9bb",
   "metadata": {},
   "source": [
    "The SQL query yielded the expected result!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
